---
- name: Configure Deployment Host
  hosts: deployment-host
  tags: deployment-host
  tasks:
    - name: Install OSA deploy dependencies
      apt: name="{{ item }}" state=latest update_cache=yes
      with_items:
        - aptitude
        - software-properties-common
        - python-pip
        - build-essential
        - libssl-dev
        - libffi-dev
        - python-dev
        - git
      tags: install

    - name: Clone OSA Repository
      git: repo=https://github.com/openstack/openstack-ansible.git
           dest=/opt/openstack-ansible
           clone=yes
           version="{{ OSA_VERSION }}"

    # The following task is a workaround for this bug:
    # https://bugs.launchpad.net/openstack-ansible/+bug/1612377
    # https://bugs.launchpad.net/ubuntu/+source/salt/+bug/1586381
    # It will go away when we upgrade to Mitaka/Newton
    # Also, why are we apparently running PIP outside of a virtual environment?
    - name: Downgrade to pip 8.1.1 prior to running bootstrap script
      apt:
        name: "{{ item }}"
        state: installed
        force: yes
      with_items:
        - python-pip-whl=8.1.1-2
        - python-pip=8.1.1-2


    - name: Run OSA bootstrap script
      shell: cd /opt/openstack-ansible && scripts/bootstrap-ansible.sh

    - name: rsync OSA dir to new directory
      shell: rsync -av /opt/openstack-ansible/etc/openstack_deploy /etc/
      # syncronize: src=/opt/openstack-ansible/etc/openstack_deploy dest=/etc/ archive=yes

    - debug: msg="Manually copy over new config by running 'cd /etc/openstack_deploy/ && cp openstack_user_config.yml.example openstack_user_config.yml'"

- name: Prepare All Target Hosts
  hosts: target-hosts
  tags: target-hosts
  tasks:
    - name: install OpenStack common tools
      apt: name={{ item }} state=latest update_cache=yes
      with_items:
        - git
        - tmux
        - vim
        - nmap
        - traceroute
      tags:
        - install

    - name: Install OSA dependencies
      apt: name="{{ item }}" state=latest update_cache=yes
      with_items:
        - aptitude
        - build-essential
        - git
        - ntp
        - ntpdate
        - openssh-server
        - python-dev
        - sudo
      tags: install

    - name: Transfer Deployment host SSH key
      authorized_key: user=root key="{{ SSH.PUBLIC_KEY }}" state=present
      tags: ssh-keys

    - name: Install OSA target host dependencies
      apt: name="{{ item }}" state=latest update_cache=yes
      with_items:
        - bridge-utils
        - debootstrap
        - ifenslave
        - ifenslave-2.6
        - lsof
        - lvm2
        - ntp
        - ntpdate
        - openssh-server
        - sudo
        - tcpdump
        - vlan
      tags: install

    # I suspect this isn't needed, handled in configure_networking.yml
    - name: enable required kernel modules
      modprobe: name="{{ item }}" state=present
      with_items:
        # - bonding
        - 8021q
      tags:
        - kernel
        - modprobe

- name: Prepare Block-Storage Host(s)
  hosts: block-storage
  tags: block-storage-hosts
  tasks:
    # - name: create the LVM physical volume
    #   lvg: vg={{ item }} pvs=/dev/{{ CINDER_PHYSICAL_VOLUME.physical_volume }} vg_options="--metadatasize {{ CINDER_PHYSICAL_VOLUME.metadatasize }}"
    #   with_items:
    #     - cinder-volumes
    #     - lxc
    #   tags:
    #     - lvm

    - name: print steps to partition disk
      debug: msg="{{ item }}"
      with_items: '{{ PARTITIONING }}'
      run_once: true
      tags:
        - lvm
        - partition

    - name: create the LVM physical volume manually
      shell: "{{ item }}"
      with_items:
        - "pvcreate --metadatasize {{ CINDER_PHYSICAL_VOLUME.metadatasize }}Mg /dev/{{ CINDER_PHYSICAL_VOLUME.physical_volume }}"
        - "vgcreate cinder-volumes /dev/{{ CINDER_PHYSICAL_VOLUME.physical_volume }}"
        # - "vgcreate lxc /dev/{{ CINDER_PHYSICAL_VOLUME.physical_volume }}"
      when: CINDER_PHYSICAL_VOLUME.create_flag is defined
      tags:
        - lvm

    - name: get LVM metadatasize
      shell: pvs --units M -o pv_mda_count,pv_mda_free,pv_mda_size /dev/{{ CINDER_PHYSICAL_VOLUME.physical_volume }}
      register: lvm_metadatasize
      tags:
        - lvm

    - name: show output LVM metadatasize
      debug: msg="{{ lvm_metadatasize.stdout }}"
      tags:
        - lvm
